// Class: ReadBDT_VBF0HighVPt
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT_VBF0HighVPt
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/09       [395785]
Creator        : ajafari
Date           : Fri Jul  5 15:52:40 2019
Host           : Linux cmsbuild49.cern.ch 2.6.32-696.10.2.el6.x86_64 #1 SMP Thu Sep 14 16:35:02 CEST 2017 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/work/a/ajafari/Vjj/CMSSW_9_4_2/src/TopLJets2015/TopAnalysis/macro/mva
Training events: 53276
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
nCuts: "0" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
SeparationType: "giniindex" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
AdaBoostBeta: "6.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "4" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 13
subleadj_pt                   subleadj_pt                   subleadj_pt                   subleadj_pt                                                     'F'    [30.0432109833,1759.34570312]
mjj                           mjj                           mjj                           mjj                                                             'F'    [500.007110596,8966.10839844]
jjpt                          jjpt                          jjpt                          jjpt                                                            'F'    [4.85194396973,1512.05419922]
detajj                        detajj                        detajj                        detajj                                                          'F'    [0.000106394290924,7.99623584747]
dphijj                        dphijj                        dphijj                        dphijj                                                          'F'    [-3.14156651497,3.14158058167]
ystar                         ystar                         ystar                         ystar                                                           'F'    [-4.43096017838,4.6264090538]
dphibjj                       dphibjj                       dphibjj                       dphibjj                                                         'F'    [-3.14158630371,3.14158272743]
j_qg[0]                       j_qg_0_                       j_qg[0]                       leadjet_qg                                                      'F'    [-1,1]
j_qg[1]                       j_qg_1_                       j_qg[1]                       subleadjet_qg                                                   'F'    [-1,1]
dphivj0                       dphivj0                       dphivj0                       dphivj0                                                         'F'    [0.00399923324585,3.14157772064]
dphivj1                       dphivj1                       dphivj1                       dphivj1                                                         'F'    [0.000400245189667,3.14157629013]
aplanarity                    aplanarity                    aplanarity                    aplanarity                                                      'F'    [7.25060690741e-13,0.399715304375]
C                             C                             C                             C                                                               'F'    [0.00490315351635,0.978911340237]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDT_VBF0HighVPtNode
   
#ifndef BDT_VBF0HighVPtNode__def
#define BDT_VBF0HighVPtNode__def
   
class BDT_VBF0HighVPtNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDT_VBF0HighVPtNode ( BDT_VBF0HighVPtNode* left,BDT_VBF0HighVPtNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDT_VBF0HighVPtNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDT_VBF0HighVPtNode*   fLeft;     // pointer to the left daughter node
   BDT_VBF0HighVPtNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDT_VBF0HighVPtNode::~BDT_VBF0HighVPtNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT_VBF0HighVPt : public IClassifierReader {

 public:

   // constructor
   ReadBDT_VBF0HighVPt( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT_VBF0HighVPt" ),
        fNvars( 13 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "subleadj_pt", "mjj", "jjpt", "detajj", "dphijj", "ystar", "dphibjj", "j_qg[0]", "j_qg[1]", "dphivj0", "dphivj1", "aplanarity", "C" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;
      fVmin[9] = 0;
      fVmax[9] = 0;
      fVmin[10] = 0;
      fVmax[10] = 0;
      fVmin[11] = 0;
      fVmax[11] = 0;
      fVmin[12] = 0;
      fVmax[12] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';
      fType[9] = 'F';
      fType[10] = 'F';
      fType[11] = 'F';
      fType[12] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT_VBF0HighVPt() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[13];
   double fVmax[13];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[13];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDT_VBF0HighVPtNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT_VBF0HighVPt::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDT_VBF0HighVPtNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDT_VBF0HighVPtNode*)current->GetRight();
         else current=(BDT_VBF0HighVPtNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT_VBF0HighVPt::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(0.38832574287289);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.707724,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46962,-99) , 
5, 1.42641, 1, 0, 0.675793,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4261,-99) , 
7, 0.174589, 0, 0, 0.637357,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.519153,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.298278,-99) , 
7, 0.559809, 0, 0, 0.445273,-99) , 
NN(
0, 
0, 
-1, 610.575, 0, -1, 0.278141,-99) , 
8, 0.798436, 0, 0, 0.367494,-99) , 
1, 863.898, 0, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.254587);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2236.02, 0, 1, 0.761383,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.632284,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.471898,-99) , 
5, -0.910327, 0, 0, 0.594567,-99) , 
1, 1686.66, 0, 0, 0.649579,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504345,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.336748,-99) , 
5, -1.18959, 0, 0, 0.474497,-99) , 
NN(
0, 
0, 
-1, 543.395, 0, -1, 0.324574,-99) , 
1, 619.155, 0, 0, 0.426725,-99) , 
1, 1065.64, 0, 0, 0.499921,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.198351);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 3.12173, 0, 1, 0.655533,-99) , 
NN(
0, 
0, 
-1, 0.0668493, 0, -1, 0.437803,-99) , 
1, 1296.38, 0, 0, 0.48377,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.201572);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2225.53, 0, 1, 0.645184,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.590907,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430411,-99) , 
7, 0.895258, 0, 0, 0.51047,-99) , 
3, 3.08521, 0, 0, 0.594858,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.530428,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.405114,-99) , 
10, 2.20213, 1, 0, 0.499152,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.344361,-99) , 
7, 0.136607, 0, 0, 0.476397,-99) , 
1, 1014.43, 0, 0, 0.518314,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.141042);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.745292,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579626,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45111,-99) , 
8, 0.389297, 0, 0, 0.54456,-99) , 
1, 2236.02, 0, 0, 0.566205,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503784,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.362975,-99) , 
8, 0.124917, 0, 0, 0.486026,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.352663,-99) , 
5, 1.19872, 1, 0, 0.463873,-99) , 
1, 1017.52, 0, 0, 0.499538,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.163407);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.717522,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558449,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.433653,-99) , 
5, 1.01413, 1, 0, 0.529423,-99) , 
1, 2236.02, 0, 0, 0.549234,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514944,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.405091,-99) , 
0, 81.5986, 0, 0, 0.491374,-99) , 
NN(
0, 
0, 
-1, 0.586079, 0, -1, 0.410649,-99) , 
7, 0.93384, 0, 0, 0.448097,-99) , 
1, 1017.52, 0, 0, 0.483182,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.105875);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.683185,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512879,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442259,-99) , 
1, 701.242, 0, 0, 0.487625,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.382212,-99) , 
5, -1.54, 0, 0, 0.475825,-99) , 
1, 2236.02, 0, 0, 0.483196,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.0842343);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.6598,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.502495,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4276,-99) , 
5, -0.851495, 0, 0, 0.481256,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.367282,-99) , 
5, 1.82329, 1, 0, 0.472791,-99) , 
1, 2236.02, 0, 0, 0.479331,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.115274);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.64062,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514357,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.451933,-99) , 
5, -0.666199, 0, 0, 0.485939,-99) , 
NN(
0, 
0, 
-1, 1.33793, 1, -1, 0.423027,-99) , 
5, 0.627513, 1, 0, 0.466163,-99) , 
1, 2236.02, 0, 0, 0.472196,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.0696937);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.633395,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.4896,-99) , 
1, 2229.68, 0, 0, 0.494676,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.397608,-99) , 
7, 0.0555568, 0, 0, 0.486421,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.369855,-99) , 
8, 0.0481844, 0, 0, 0.479066,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.0578518);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.768203, 1, 1, 0.511974,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.414923,-99) , 
7, 0.0555568, 0, 0, 0.503777,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.386995,-99) , 
8, 0.0481844, 0, 0, 0.496467,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.106826);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.570151,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.47831,-99) , 
8, 0.454153, 0, 0, 0.543643,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532055,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.462262,-99) , 
6, 3.06088, 0, 0, 0.479791,-99) , 
6, -3.0653, 1, 0, 0.492159,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.383564,-99) , 
1, 530.369, 0, 0, 0.486127,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.108606);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 1101.99, 0, 1, 0.543481,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450181,-99) , 
12, 0.219215, 0, 0, 0.527872,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.61034,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459578,-99) , 
9, 2.85719, 1, 0, 0.527536,-99) , 
NN(
0, 
0, 
-1, 0.287481, 1, -1, 0.463798,-99) , 
3, 3.69783, 0, 0, 0.480263,-99) , 
8, 0.960793, 0, 0, 0.496499,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.0774213);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.416374, 1, 1, 0.542402,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556422,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.483859,-99) , 
3, 1.04244, 1, 0, 0.495929,-99) , 
6, -2.96479, 1, 0, 0.510992,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432495,-99) , 
1, 543.395, 0, 0, 0.504781,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.0475879);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575381,-99) , 
NN(
NN(
0, 
0, 
-1, 0.597671, 1, 1, 0.508928,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438284,-99) , 
7, 0.0668493, 0, 0, 0.502109,-99) , 
1, 1668.94, 0, 0, 0.50903,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.0719429);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.563711,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527387,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482234,-99) , 
7, 0.812814, 0, 0, 0.508121,-99) , 
NN(
0, 
0, 
-1, 2.89619, 1, -1, 0.46879,-99) , 
5, 0.334942, 1, 0, 0.49251,-99) , 
1, 1668.94, 0, 0, 0.499217,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.118635);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.570854,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421158,-99) , 
5, 1.56577, 1, 0, 0.546581,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.412507,-99) , 
5, -1.38665, 0, 0, 0.524538,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55697,-99) , 
NN(
0, 
0, 
-1, 0.386706, 0, -1, 0.474518,-99) , 
5, -1.23341, 1, 0, 0.486511,-99) , 
3, 2.96214, 0, 0, 0.502885,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.0733267);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 3.63973, 0, 1, 0.525233,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514098,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438942,-99) , 
0, 118.529, 0, 0, 0.473967,-99) , 
10, 2.3781, 1, 0, 0.515967,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.427951,-99) , 
0, 60.7328, 0, 0, 0.510478,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.050463);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.0227491, 1, 1, 0.545541,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621216,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491818,-99) , 
1, 2191.31, 0, 0, 0.496652,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.415382,-99) , 
5, -1.86597, 0, 0, 0.490939,-99) , 
3, 0.765261, 1, 0, 0.497812,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.0651716);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.578443,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.542124,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49495,-99) , 
3, 3.13489, 0, 0, 0.511646,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513877,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.394279,-99) , 
10, 0.583897, 1, 0, 0.45836,-99) , 
9, 3.04, 1, 0, 0.502989,-99) , 
6, 3.12432, 0, 0, 0.506799,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.089674);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.53919,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491693,-99) , 
9, 2.1835, 0, 0, 0.532127,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.462693,-99) , 
4, -2.75008, 0, 0, 0.524709,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538571,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479249,-99) , 
12, 0.388316, 0, 0, 0.510351,-99) , 
NN(
0, 
0, 
-1, 2.60081, 0, -1, 0.435664,-99) , 
10, 1.47236, 1, 0, 0.486291,-99) , 
9, 2.89788, 1, 0, 0.509881,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0463546);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2256.61, 0, 1, 0.51402,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442183,-99) , 
8, 0.0481844, 0, 0, 0.509636,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438936,-99) , 
5, -1.94075, 0, 0, 0.505474,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0360066);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561521,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503984,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459456,-99) , 
9, 3.04, 1, 0, 0.496757,-99) , 
6, 3.12511, 0, 0, 0.499869,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.440498,-99) , 
1, 530.369, 0, 0, 0.49659,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0521958);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.564273,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.494708,-99) , 
11, 0.000900592, 1, 0, 0.525854,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.546337,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489929,-99) , 
11, 0.00028758, 1, 0, 0.494065,-99) , 
NN(
0, 
0, 
-1, 82.9117, 0, -1, 0.439966,-99) , 
9, 3.00153, 1, 0, 0.485619,-99) , 
10, 0.396715, 1, 0, 0.491245,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.0366869);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 197.264, 0, 1, 0.539156,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505564,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.449087,-99) , 
5, -1.84948, 0, 0, 0.501566,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447689,-99) , 
0, 360.301, 1, 0, 0.497042,-99) , 
8, 0.997596, 0, 0, 0.501536,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.0424584);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.622148, 1, 1, 0.531852,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.574313,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491,-99) , 
1, 2191.31, 0, 0, 0.494087,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430249,-99) , 
5, 1.86352, 1, 0, 0.489473,-99) , 
3, 0.765261, 1, 0, 0.494821,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0396473);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.569306,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509519,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480984,-99) , 
12, 0.2794, 0, 0, 0.502703,-99) , 
6, 3.12402, 0, 0, 0.505858,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.459329,-99) , 
0, 63.2857, 0, 0, 0.5023,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.0716231);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2.75119, 1, 1, 0.526201,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527903,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452959,-99) , 
12, 0.480662, 0, 0, 0.479121,-99) , 
2, 195.898, 0, 0, 0.509241,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509835,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.458637,-99) , 
0, 111.819, 0, 0, 0.492608,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.430132,-99) , 
0, 324.098, 1, 0, 0.483285,-99) , 
2, 275.582, 1, 0, 0.498105,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0432398);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.550178,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507476,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48175,-99) , 
4, 1.47612, 0, 0, 0.491758,-99) , 
6, 3.12517, 0, 0, 0.494557,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.444014,-99) , 
1, 530.369, 0, 0, 0.491767,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0559572);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.534628,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.477148,-99) , 
2, 323.128, 1, 0, 0.514467,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.507888,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474417,-99) , 
8, 0.809036, 1, 0, 0.489695,-99) , 
1, 1065.31, 0, 0, 0.497346,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45481,-99) , 
7, 0.048224, 0, 0, 0.494148,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0581823);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2.7556, 1, 1, 0.519555,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511336,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466776,-99) , 
6, -2.92093, 1, 0, 0.492865,-99) , 
6, 2.88634, 0, 0, 0.503018,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.513192,-99) , 
NN(
0, 
0, 
-1, 2.89385, 1, -1, 0.454853,-99) , 
3, 3.91956, 0, 0, 0.465969,-99) , 
8, 0.302941, 0, 0, 0.494935,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.0493334);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55724,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.494163,-99) , 
0, 197.264, 0, 0, 0.528902,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.528255,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48487,-99) , 
10, 0.396715, 1, 0, 0.489652,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445319,-99) , 
9, 3.10603, 1, 0, 0.486932,-99) , 
8, 0.997574, 0, 0, 0.491423,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.0764503);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.529401,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452158,-99) , 
5, -1.37456, 0, 0, 0.51577,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.554628,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.47506,-99) , 
5, -1.19811, 1, 0, 0.487063,-99) , 
3, 2.31995, 0, 0, 0.503161,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460504,-99) , 
5, 1.86352, 1, 0, 0.500177,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0676234);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561333,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541253,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481144,-99) , 
4, -2.34083, 1, 0, 0.505592,-99) , 
11, 0.00686397, 1, 0, 0.521709,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515361,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.469371,-99) , 
5, -1.01952, 0, 0, 0.502412,-99) , 
NN(
0, 
0, 
-1, 0.0041814, 0, -1, 0.450693,-99) , 
5, 1.267, 1, 0, 0.493348,-99) , 
3, 1.50823, 1, 0, 0.500664,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.0496771);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561136,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55428,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482235,-99) , 
5, -0.766283, 1, 0, 0.505563,-99) , 
5, 0.741236, 0, 0, 0.519229,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539188,-99) , 
NN(
0, 
0, 
-1, 166.975, 1, -1, 0.486808,-99) , 
9, 2.14925, 1, 0, 0.49025,-99) , 
3, 1.50823, 1, 0, 0.497721,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.0410743);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 2.81652, 0, 1, 0.515677,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.557952,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495671,-99) , 
6, 3.10232, 0, 0, 0.504492,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.456994,-99) , 
0, 73.2422, 0, 0, 0.493864,-99) , 
9, 2.85718, 1, 0, 0.505931,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0533232);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.999019, 1, 1, 0.533759,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.562734,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48374,-99) , 
1, 566.22, 0, 0, 0.520438,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521859,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48593,-99) , 
7, 0.993553, 0, 0, 0.494529,-99) , 
1, 622.431, 1, 0, 0.500304,-99) , 
8, 0.997574, 0, 0, 0.503882,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0351166);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.997373, 0, 1, 0.513089,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.480559,-99) , 
7, 0.99882, 1, 0, 0.509911,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.471223,-99) , 
8, 0.0481844, 0, 0, 0.507554,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.0216272);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.57993,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.535791,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49776,-99) , 
2, 432.682, 0, 0, 0.501205,-99) , 
1, 2149.12, 0, 0, 0.503589,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.467203,-99) , 
0, 417.215, 1, 0, 0.50147,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.033706);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.574651,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514142,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.492962,-99) , 
5, 0.334942, 1, 0, 0.505681,-99) , 
1, 2149.12, 0, 0, 0.507766,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.472667,-99) , 
0, 417.215, 1, 0, 0.505722,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.06375);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.573284,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.498549,-99) , 
12, 0.525461, 1, 0, 0.541491,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537231,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491853,-99) , 
8, 0.982282, 0, 0, 0.503852,-99) , 
5, 0.224221, 1, 0, 0.5125,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.529593,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.468927,-99) , 
9, 2.99178, 1, 0, 0.51258,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.516187,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452469,-99) , 
5, -1.07383, 1, 0, 0.479341,-99) , 
3, 2.92479, 0, 0, 0.494023,-99) , 
5, -0.233835, 0, 0, 0.504462,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.0560888);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 554.136, 0, 1, 0.543779,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.518699,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466654,-99) , 
10, 2.46143, 1, 0, 0.51059,-99) , 
1, 620.134, 1, 0, 0.517858,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.548909,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.486059,-99) , 
10, 1.56363, 1, 0, 0.518269,-99) , 
NN(
0, 
0, 
-1, 3.02491, 1, -1, 0.483943,-99) , 
11, 0.00114006, 1, 0, 0.492394,-99) , 
5, -0.233835, 0, 0, 0.506785,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0589681);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556327,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524596,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463408,-99) , 
11, 0.0298281, 1, 0, 0.497169,-99) , 
2, 265.151, 1, 0, 0.521492,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541797,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.510208,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.468422,-99) , 
0, 166.855, 1, 0, 0.496317,-99) , 
3, 0.909085, 1, 0, 0.500466,-99) , 
12, 0.604086, 0, 0, 0.505415,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.044737);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.539649,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525999,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.491234,-99) , 
12, 0.640827, 0, 0, 0.498574,-99) , 
11, 0.000342703, 1, 0, 0.503393,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51228,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442018,-99) , 
12, 0.390182, 1, 0, 0.479088,-99) , 
0, 79.4754, 0, 0, 0.499361,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.0252507);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 4.54502, 0, 1, 0.507858,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501927,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.440836,-99) , 
9, 3.01541, 1, 0, 0.47846,-99) , 
0, 79.4754, 0, 0, 0.502984,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.0330481);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.560889,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536003,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493835,-99) , 
5, 1.43848, 0, 0, 0.498888,-99) , 
3, 4.54502, 0, 0, 0.501545,-99) , 
NN(
0, 
0, 
-1, 3.01541, 1, -1, 0.476996,-99) , 
0, 79.4754, 0, 0, 0.497477,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0204229);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.531719,-99) , 
NN(
NN(
0, 
0, 
-1, 0.175663, 1, 1, 0.504363,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.474983,-99) , 
7, 0.0777028, 0, 0, 0.501256,-99) , 
9, 2.12106, 1, 0, 0.503629,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0210733);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.548306,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.54055,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.498423,-99) , 
6, 3.11685, 0, 0, 0.501163,-99) , 
3, 4.54502, 0, 0, 0.503178,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503659,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455842,-99) , 
12, 0.390182, 1, 0, 0.481101,-99) , 
0, 79.4754, 0, 0, 0.49952,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.0318399);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 1183.33, 1, 1, 0.519184,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525928,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495646,-99) , 
2, 343.353, 0, 0, 0.501729,-99) , 
1, 1056.4, 0, 0, 0.50738,-99) , 
NN(
0, 
0, 
-1, 0.462504, 1, -1, 0.480803,-99) , 
0, 79.4754, 0, 0, 0.502977,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0293262);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 131.87, 1, 1, 0.517734,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.527953,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.496314,-99) , 
6, -3.08578, 1, 0, 0.501534,-99) , 
11, 0.0182503, 0, 0, 0.506907,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.463678,-99) , 
3, 4.82608, 1, 0, 0.504865,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT_VBF0HighVPt::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT_VBF0HighVPt::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
