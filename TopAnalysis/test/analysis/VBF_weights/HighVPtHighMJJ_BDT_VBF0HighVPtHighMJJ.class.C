// Class: ReadBDT_VBF0HighVPtHighMJJ
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : BDT::BDT_VBF0HighVPtHighMJJ
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/09       [395785]
Creator        : ajafari
Date           : Wed Mar 13 15:45:12 2019
Host           : Linux cmsbuild49.cern.ch 2.6.32-696.10.2.el6.x86_64 #1 SMP Thu Sep 14 16:35:02 CEST 2017 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /afs/cern.ch/work/a/ajafari/Vjj/CMSSW_9_4_2/src/TopLJets2015/TopAnalysis/macro
Training events: 26262
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "False" [Print method-specific help message]
CreateMVAPdfs: "True" [Create PDFs for classifier outputs (signal and background)]
nCuts: "0" [Number of grid points in variable range used in finding optimal cut in node splitting]
BoostType: "AdaBoost" [Boosting type for the trees in the forest (note: AdaCost is still experimental)]
NegWeightTreatment: "inverseboostnegweights" [How to treat events with negative weights in the BDT training (particular the boosting) : IgnoreInTraining;  Boost With inverse boostweight; Pair events with negative and positive weights in training sample and *annihilate* them (experimental!)]
SeparationType: "giniindex" [Separation criterion for node splitting]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
NTrees: "50" [Number of trees in the forest]
MaxDepth: "3" [Max depth of the decision tree allowed]
MinNodeSize: "5%" [Minimum percentage of training events required in a leaf node (default: Classification: 5%, Regression: 0.2%)]
AdaBoostR2Loss: "quadratic" [Type of Loss function in AdaBoostR2]
UseBaggedBoost: "False" [Use only a random subsample of all events for growing the trees in each boost iteration.]
Shrinkage: "1.000000e+00" [Learning rate for GradBoost algorithm]
AdaBoostBeta: "6.000000e-01" [Learning rate  for AdaBoost algorithm]
UseRandomisedTrees: "False" [Determine at each node splitting the cut variable only as the best out of a random subset of variables (like in RandomForests)]
UseNvars: "3" [Size of the subset of variables used with RandomisedTree option]
UsePoissonNvars: "True" [Interpret "UseNvars" not as fixed number but as mean of a Poisson distribution in each split with RandomisedTree option]
BaggedSampleFraction: "6.000000e-01" [Relative size of bagged event sample to original size of the data sample (used whenever bagging is used (i.e. UseBaggedBoost, Bagging,)]
UseYesNoLeaf: "True" [Use Sig or Bkg categories, or the purity=S/(S+B) as classification of the leaf node -> Real-AdaBoost]
Css: "1.000000e+00" [AdaCost: cost of true signal selected signal]
Cts_sb: "1.000000e+00" [AdaCost: cost of true signal selected bkg]
Ctb_ss: "1.000000e+00" [AdaCost: cost of true bkg    selected signal]
Cbb: "1.000000e+00" [AdaCost: cost of true bkg    selected bkg ]
NodePurityLimit: "5.000000e-01" [In boosting/pruning, nodes with purity > NodePurityLimit are signal; background otherwise.]
RegressionLossFunctionBDTG: "huber" [Loss function for BDTG regression.]
HuberQuantile: "7.000000e-01" [In the Huber loss function this is the quantile that separates the core from the tails in the residuals distribution.]
DoBoostMonitor: "False" [Create control plot with ROC integral vs tree number]
UseFisherCuts: "False" [Use multivariate splits using the Fisher criterion]
MinLinCorrForFisher: "8.000000e-01" [The minimum linear correlation between two variables demanded for use in Fisher criterion in node splitting]
UseExclusiveVars: "False" [Variables already used in fisher criterion are not anymore analysed individually for node splitting]
DoPreselection: "False" [and and apply automatic pre-selection for 100% efficient signal (bkg) cuts prior to training]
SigToBkgFraction: "1.000000e+00" [Sig to Bkg ratio used in Training (similar to NodePurityLimit, which cannot be used in real adaboost]
PruneMethod: "nopruning" [Note: for BDTs use small trees (e.g.MaxDepth=3) and NoPruning:  Pruning: Method used for pruning (removal) of statistically insignificant branches ]
PruneStrength: "0.000000e+00" [Pruning strength]
PruningValFraction: "5.000000e-01" [Fraction of events to use for optimizing automatic pruning.]
SkipNormalization: "False" [Skip normalization at initialization, to keep expectation value of BDT output according to the fraction of events]
nEventsMin: "0" [deprecated: Use MinNodeSize (in % of training events) instead]
UseBaggedGrad: "False" [deprecated: Use *UseBaggedBoost* instead:  Use only a random subsample of all events for growing the trees in each iteration.]
GradBaggingFraction: "6.000000e-01" [deprecated: Use *BaggedSampleFraction* instead: Defines the fraction of events to be used in each iteration, e.g. when UseBaggedGrad=kTRUE. ]
UseNTrainEvents: "0" [deprecated: Use *BaggedSampleFraction* instead: Number of randomly picked training events used in randomised (and bagged) trees]
NNodesMax: "0" [deprecated: Use MaxDepth instead to limit the tree size]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 9
ystar                         ystar                         ystar                         ystar                                                           'F'    [-3.5614168644,3.07476449013]
mjj                           mjj                           mjj                           			 mjj                                                         'F'    [1000.02545166,9690.50488281]
j_qg[0]                       j_qg_0_                       j_qg[0]                       			 leadjet_qg                                                  'F'    [-1,1]
circularity                   circularity                   circularity                   		 circularity                                                  'F'    [0.00168784300331,0.897996246815]
sphericity                    sphericity                    sphericity                    		 sphericity                                                   'F'    [0.00536917801946,0.533853709698]
j_qg[1]                       j_qg_1_                       j_qg[1]                       			 subleadj_qg                                                 'F'    [-1,1]
jjpt                          jjpt                          jjpt                          			 jjpt                                                        'F'    [1.5927734375,636.596374512]
dphijj                        dphijj                        dphijj                        			 dphijj                                                      'F'    [-3.14146089554,3.14152264595]
j_pt[0]+j_pt[1]+gamma_pt[0]     j_pt_0__P_j_pt_1__P_gamma_pt_0_ j_pt[0]+j_pt[1]+gamma_pt[0]     syspt                                                               'F'    [177.845947266,1807.64550781]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#define NN new BDT_VBF0HighVPtHighMJJNode
   
#ifndef BDT_VBF0HighVPtHighMJJNode__def
#define BDT_VBF0HighVPtHighMJJNode__def
   
class BDT_VBF0HighVPtHighMJJNode {
   
public:
   
   // constructor of an essentially "empty" node floating in space
   BDT_VBF0HighVPtHighMJJNode ( BDT_VBF0HighVPtHighMJJNode* left,BDT_VBF0HighVPtHighMJJNode* right,
                          int selector, double cutValue, bool cutType, 
                          int nodeType, double purity, double response ) :
   fLeft         ( left         ),
   fRight        ( right        ),
   fSelector     ( selector     ),
   fCutValue     ( cutValue     ),
   fCutType      ( cutType      ),
   fNodeType     ( nodeType     ),
   fPurity       ( purity       ),
   fResponse     ( response     ){
   }

   virtual ~BDT_VBF0HighVPtHighMJJNode();

   // test event if it descends the tree at this node to the right
   virtual bool GoesRight( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetRight( void )  {return fRight; };

   // test event if it descends the tree at this node to the left 
   virtual bool GoesLeft ( const std::vector<double>& inputValues ) const;
   BDT_VBF0HighVPtHighMJJNode* GetLeft( void ) { return fLeft; };   

   // return  S/(S+B) (purity) at this node (from  training)

   double GetPurity( void ) const { return fPurity; } 
   // return the node type
   int    GetNodeType( void ) const { return fNodeType; }
   double GetResponse(void) const {return fResponse;}

private:

   BDT_VBF0HighVPtHighMJJNode*   fLeft;     // pointer to the left daughter node
   BDT_VBF0HighVPtHighMJJNode*   fRight;    // pointer to the right daughter node
   int                     fSelector; // index of variable used in node selection (decision tree)   
   double                  fCutValue; // cut value applied on this node to discriminate bkg against sig
   bool                    fCutType;  // true: if event variable > cutValue ==> signal , false otherwise
   int                     fNodeType; // Type of node: -1 == Bkg-leaf, 1 == Signal-leaf, 0 = internal 
   double                  fPurity;   // Purity of node from training
   double                  fResponse; // Regression response value of node
}; 
   
//_______________________________________________________________________
   BDT_VBF0HighVPtHighMJJNode::~BDT_VBF0HighVPtHighMJJNode()
{
   if (fLeft  != NULL) delete fLeft;
   if (fRight != NULL) delete fRight;
}; 
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesRight( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the right
   bool result;
     result = (inputValues[fSelector] > fCutValue );
   if (fCutType == true) return result; //the cuts are selecting Signal ;
   else return !result;
}
   
//_______________________________________________________________________
bool BDT_VBF0HighVPtHighMJJNode::GoesLeft( const std::vector<double>& inputValues ) const
{
   // test event if it descends the tree at this node to the left
   if (!this->GoesRight(inputValues)) return true;
   else return false;
}
   
#endif
   
#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadBDT_VBF0HighVPtHighMJJ : public IClassifierReader {

 public:

   // constructor
   ReadBDT_VBF0HighVPtHighMJJ( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadBDT_VBF0HighVPtHighMJJ" ),
        fNvars( 9 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "ystar", "mjj", "j_qg[0]", "circularity", "sphericity", "j_qg[1]", "jjpt", "dphijj", "j_pt[0]+j_pt[1]+gamma_pt[0]" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;
      fVmin[4] = 0;
      fVmax[4] = 0;
      fVmin[5] = 0;
      fVmax[5] = 0;
      fVmin[6] = 0;
      fVmax[6] = 0;
      fVmin[7] = 0;
      fVmax[7] = 0;
      fVmin[8] = 0;
      fVmax[8] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';
      fType[4] = 'F';
      fType[5] = 'F';
      fType[6] = 'F';
      fType[7] = 'F';
      fType[8] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadBDT_VBF0HighVPtHighMJJ() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[9];
   double fVmax[9];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[9];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   std::vector<BDT_VBF0HighVPtHighMJJNode*> fForest;       // i.e. root nodes of decision trees
   std::vector<double>                fBoostWeights; // the weights applied in the individual boosts
};

double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue__( const std::vector<double>& inputValues ) const
{
   double myMVA = 0;
   double norm  = 0;
   for (unsigned int itree=0; itree<fForest.size(); itree++){
      BDT_VBF0HighVPtHighMJJNode *current = fForest[itree];
      while (current->GetNodeType() == 0) { //intermediate node
         if (current->GoesRight(inputValues)) current=(BDT_VBF0HighVPtHighMJJNode*)current->GetRight();
         else current=(BDT_VBF0HighVPtHighMJJNode*)current->GetLeft();
      }
      myMVA += fBoostWeights[itree] *  current->GetNodeType();
      norm  += fBoostWeights[itree];
   }
   return myMVA /= norm;
};

void ReadBDT_VBF0HighVPtHighMJJ::Initialize()
{
  // itree = 0
  fBoostWeights.push_back(0.372145331633741);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 175.813, 1, 1, 0.734443,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556958,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.31689,-99) , 
0, 0.787898, 1, 0, 0.474451,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.189289,-99) , 
0, -1.59123, 0, 0, 0.437265,-99) , 
1, 1734.24, 0, 0, 0.5,-99)    );
  // itree = 1
  fBoostWeights.push_back(0.227496);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2134.27, 0, 1, 0.697111,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.495757,-99) , 
6, 175.813, 1, 0, 0.655455,-99) , 
NN(
0, 
0, 
-1, -1.1605, 0, -1, 0.42258,-99) , 
1, 1734.24, 0, 0, 0.470009,-99)    );
  // itree = 2
  fBoostWeights.push_back(0.291402);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.604784,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.404391,-99) , 
2, 0.212397, 0, 0, 0.573845,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.346271,-99) , 
0, 1.52213, 1, 0, 0.544196,-99) , 
NN(
0, 
0, 
-1, -1.68129, 0, -1, 0.330579,-99) , 
0, -1.34719, 0, 0, 0.511317,-99)    );
  // itree = 3
  fBoostWeights.push_back(0.234711);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.635905,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.485017,-99) , 
6, 167.073, 1, 0, 0.600371,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.428488,-99) , 
5, 0.178244, 0, 0, 0.572505,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.615432,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.472571,-99) , 
5, 0.678094, 0, 0, 0.544276,-99) , 
NN(
0, 
0, 
-1, 312.344, 0, -1, 0.398361,-99) , 
3, 0.558002, 0, 0, 0.439895,-99) , 
1, 1401.93, 0, 0, 0.494073,-99)    );
  // itree = 4
  fBoostWeights.push_back(0.229221);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.601406,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.451136,-99) , 
0, 1.39496, 1, 0, 0.574374,-99) , 
NN(
0, 
0, 
-1, 1202.31, 0, -1, 0.427289,-99) , 
0, -0.91288, 0, 0, 0.535537,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.349405,-99) , 
8, 261.796, 0, 0, 0.513657,-99)    );
  // itree = 5
  fBoostWeights.push_back(0.16859);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.659097,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.545377,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.434014,-99) , 
6, 151.175, 1, 0, 0.511659,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.375561,-99) , 
8, 261.796, 0, 0, 0.495067,-99) , 
1, 2134.27, 0, 0, 0.510525,-99)    );
  // itree = 6
  fBoostWeights.push_back(0.188175);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 2259.98, 0, 1, 0.596411,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.53859,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.410225,-99) , 
6, 116.914, 1, 0, 0.475451,-99) , 
1, 1169.93, 0, 0, 0.556283,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.536984,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.405636,-99) , 
2, 0.198586, 0, 0, 0.517074,-99) , 
NN(
0, 
0, 
-1, 2.06781, 0, -1, 0.384046,-99) , 
8, 369.741, 0, 0, 0.464832,-99) , 
3, 0.507506, 0, 0, 0.498217,-99)    );
  // itree = 7
  fBoostWeights.push_back(0.114261);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.599452,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511576,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.39217,-99) , 
4, 0.0456583, 0, 0, 0.49622,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511984,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.381893,-99) , 
7, -1.68556, 1, 0, 0.428583,-99) , 
5, 0.414143, 0, 0, 0.474212,-99) , 
1, 2134.27, 0, 0, 0.485735,-99)    );
  // itree = 8
  fBoostWeights.push_back(0.0997512);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.621912,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505379,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.379694,-99) , 
8, 668.806, 1, 0, 0.492742,-99) , 
NN(
0, 
0, 
-1, 1.67322, 0, -1, 0.435394,-99) , 
1, 1250.89, 0, 0, 0.466845,-99) , 
1, 2727, 0, 0, 0.47243,-99)    );
  // itree = 9
  fBoostWeights.push_back(0.12705);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.598188,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.549077,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.440125,-99) , 
0, -0.648394, 0, 0, 0.511048,-99) , 
NN(
0, 
0, 
-1, -1.24054, 1, -1, 0.449664,-99) , 
7, 2.37845, 0, 0, 0.467311,-99) , 
1, 2727, 0, 0, 0.471984,-99)    );
  // itree = 10
  fBoostWeights.push_back(0.169459);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.213179, 1, 1, 0.571063,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.601787,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452761,-99) , 
1, 1538.18, 0, 0, 0.492108,-99) , 
0, -0.190166, 0, 0, 0.533399,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.581029,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.455489,-99) , 
7, -2.92318, 0, 0, 0.530836,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501985,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.303581,-99) , 
7, 2.06834, 0, 0, 0.426867,-99) , 
7, -2.24317, 1, 0, 0.46544,-99) , 
3, 0.507506, 0, 0, 0.490251,-99)    );
  // itree = 11
  fBoostWeights.push_back(0.117029);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 316.547, 1, 1, 0.529487,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.439714,-99) , 
6, 62.4049, 0, 0, 0.516754,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51296,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438944,-99) , 
3, 0.402068, 0, 0, 0.476339,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.36505,-99) , 
7, 1.70004, 0, 0, 0.449429,-99) , 
7, -1.24054, 1, 0, 0.479478,-99)    );
  // itree = 12
  fBoostWeights.push_back(0.107903);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575655,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.541485,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46311,-99) , 
3, 0.162286, 1, 0, 0.47323,-99) , 
1, 2277.17, 0, 0, 0.47993,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.377486,-99) , 
6, 217.965, 1, 0, 0.473899,-99)    );
  // itree = 13
  fBoostWeights.push_back(0.0922695);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.118662, 0, 1, 0.524598,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.538207,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.453554,-99) , 
7, -2.39493, 1, 0, 0.474257,-99) , 
0, 0.318933, 1, 0, 0.50331,-99) , 
NN(
0, 
0, 
-1, 0.849055, 0, -1, 0.436065,-99) , 
8, 551.439, 1, 0, 0.491609,-99)    );
  // itree = 14
  fBoostWeights.push_back(0.107492);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.591667,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.557347,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.479252,-99) , 
6, 154.486, 0, 0, 0.501787,-99) , 
8, 280.63, 1, 0, 0.520309,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.540466,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.471277,-99) , 
5, 0.690914, 0, 0, 0.507412,-99) , 
NN(
0, 
0, 
-1, 2.06834, 0, -1, 0.448664,-99) , 
7, -2.25631, 1, 0, 0.470526,-99) , 
3, 0.507506, 0, 0, 0.488788,-99)    );
  // itree = 15
  fBoostWeights.push_back(0.0783709);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.521502,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.439212,-99) , 
0, 1.67479, 1, 0, 0.513708,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.424185,-99) , 
4, 0.0329674, 0, 0, 0.508115,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.424249,-99) , 
0, -1.68932, 0, 0, 0.500636,-99)    );
  // itree = 16
  fBoostWeights.push_back(0.0915359);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.55653,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.483727,-99) , 
2, 0.968594, 0, 0, 0.504665,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.52248,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.41641,-99) , 
2, 0.824036, 1, 0, 0.468115,-99) , 
6, 83.0712, 0, 0, 0.495081,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.407089,-99) , 
6, 217.965, 1, 0, 0.489929,-99)    );
  // itree = 17
  fBoostWeights.push_back(0.0824161);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.594013,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.508759,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441563,-99) , 
1, 1069.83, 0, 0, 0.49917,-99) , 
6, 93.7701, 1, 0, 0.507959,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.56475,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435755,-99) , 
8, 356.498, 1, 0, 0.499019,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.425862,-99) , 
4, 0.0637342, 0, 0, 0.468608,-99) , 
6, 83.0712, 0, 0, 0.49826,-99)    );
  // itree = 18
  fBoostWeights.push_back(0.0528624);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.577389,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.505843,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.469037,-99) , 
4, 0.076862, 0, 0, 0.490908,-99) , 
1, 2727, 0, 0, 0.493646,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.413322,-99) , 
6, 217.965, 1, 0, 0.48893,-99)    );
  // itree = 19
  fBoostWeights.push_back(0.052406);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.561459,-99) , 
NN(
0, 
0, 
-1, 0.178398, 0, -1, 0.485885,-99) , 
1, 2134.27, 0, 0, 0.491705,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.416989,-99) , 
8, 668.806, 1, 0, 0.487054,-99)    );
  // itree = 20
  fBoostWeights.push_back(0.0589814);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.51407,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.446528,-99) , 
2, 0.998475, 1, 0, 0.50934,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.5128,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.417033,-99) , 
3, 0.450905, 0, 0, 0.460853,-99) , 
5, 0.178398, 0, 0, 0.502341,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421356,-99) , 
8, 695.103, 1, 0, 0.498336,-99)    );
  // itree = 21
  fBoostWeights.push_back(0.0911395);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 423.744, 1, 1, 0.564479,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.457919,-99) , 
0, -0.478915, 0, 0, 0.520047,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.567182,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490255,-99) , 
4, 0.0571706, 1, 0, 0.504247,-99) , 
NN(
0, 
0, 
-1, -2.25793, 1, -1, 0.443864,-99) , 
3, 0.393394, 0, 0, 0.481448,-99) , 
7, 2.66058, 0, 0, 0.488921,-99)    );
  // itree = 22
  fBoostWeights.push_back(0.0731661);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.581213,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490122,-99) , 
1, 1264.36, 0, 0, 0.53726,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.512023,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466072,-99) , 
3, 0.396099, 0, 0, 0.494101,-99) , 
7, -2.28531, 1, 0, 0.507054,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.443621,-99) , 
4, 0.0346954, 0, 0, 0.502489,-99)    );
  // itree = 23
  fBoostWeights.push_back(0.0519168);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.572889,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.530294,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.489654,-99) , 
4, 0.112565, 0, 0, 0.501934,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442691,-99) , 
2, 0.0900426, 0, 0, 0.497755,-99) , 
3, 0.0810365, 1, 0, 0.501059,-99)    );
  // itree = 24
  fBoostWeights.push_back(0.100713);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 83.071, 0, 1, 0.530472,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.535424,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.431956,-99) , 
8, 404.718, 0, 0, 0.485288,-99) , 
6, 127.56, 1, 0, 0.513406,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.528147,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.407848,-99) , 
2, 0.849055, 0, 0, 0.47063,-99) , 
8, 551.439, 1, 0, 0.50597,-99)    );
  // itree = 25
  fBoostWeights.push_back(0.037303);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.58814,-99) , 
NN(
0, 
0, 
-1, 73.1303, 0, -1, 0.492137,-99) , 
6, 62.1871, 1, 0, 0.496873,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.432031,-99) , 
6, 47.3673, 0, 0, 0.492584,-99)    );
  // itree = 26
  fBoostWeights.push_back(0.0408141);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579595,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.506542,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435297,-99) , 
6, 73.1303, 0, 0, 0.501502,-99) , 
6, 62.1871, 1, 0, 0.505332,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441198,-99) , 
6, 47.4303, 0, 0, 0.501089,-99)    );
  // itree = 27
  fBoostWeights.push_back(0.0701782);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.535718,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46462,-99) , 
4, 0.0993224, 1, 0, 0.517311,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.506951,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.465441,-99) , 
6, 138.321, 0, 0, 0.485071,-99) , 
8, 362.304, 1, 0, 0.497851,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.44936,-99) , 
0, -1.68932, 0, 0, 0.493516,-99)    );
  // itree = 28
  fBoostWeights.push_back(0.0460605);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.590662,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.493385,-99) , 
3, 0.700865, 0, 0, 0.500494,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.435849,-99) , 
3, 0.784219, 1, 0, 0.496825,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.425059,-99) , 
6, 217.385, 1, 0, 0.492577,-99)    );
  // itree = 29
  fBoostWeights.push_back(0.0383425);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.700865, 0, 1, 0.510534,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.44955,-99) , 
3, 0.777278, 1, 0, 0.506795,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.436388,-99) , 
6, 217.385, 1, 0, 0.502638,-99)    );
  // itree = 30
  fBoostWeights.push_back(0.0828905);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 106.881, 0, 1, 0.550042,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.447434,-99) , 
3, 0.371793, 1, 0, 0.52488,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.556483,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48697,-99) , 
7, -2.72751, 0, 0, 0.516901,-99) , 
NN(
0, 
0, 
-1, 0.396039, 0, -1, 0.470139,-99) , 
7, -2.28531, 1, 0, 0.48816,-99) , 
7, 2.66058, 0, 0, 0.49529,-99)    );
  // itree = 31
  fBoostWeights.push_back(0.0568926);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, -0.118567, 0, 1, 0.52418,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500901,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.450938,-99) , 
6, 82.2297, 0, 0, 0.488411,-99) , 
0, 0.306018, 1, 0, 0.508889,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.531125,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.436206,-99) , 
5, 0.0891927, 1, 0, 0.477928,-99) , 
5, 0.178244, 0, 0, 0.504448,-99)    );
  // itree = 32
  fBoostWeights.push_back(0.0402733);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.579458,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.503604,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.468007,-99) , 
4, 0.0614552, 0, 0, 0.493875,-99) , 
3, 0.088199, 1, 0, 0.497909,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.439215,-99) , 
5, 0.997975, 1, 0, 0.495113,-99)    );
  // itree = 33
  fBoostWeights.push_back(0.0809713);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.59643,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.569332,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.484439,-99) , 
6, 107.139, 0, 0, 0.496292,-99) , 
1, 2052.02, 0, 0, 0.504565,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.562527,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.517223,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.460537,-99) , 
7, -2.56834, 1, 0, 0.469529,-99) , 
7, 2.77239, 0, 0, 0.477513,-99) , 
6, 116.793, 1, 0, 0.491,-99)    );
  // itree = 34
  fBoostWeights.push_back(0.119776);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.568468,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.465497,-99) , 
4, 0.100007, 1, 0, 0.539953,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.526629,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.418369,-99) , 
1, 1397.48, 1, 0, 0.486681,-99) , 
2, 0.850114, 1, 0, 0.514737,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.546154,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.481813,-99) , 
4, 0.113363, 0, 0, 0.510368,-99) , 
NN(
0, 
0, 
-1, 1513.23, 0, -1, 0.437074,-99) , 
2, 0.752957, 0, 0, 0.480953,-99) , 
8, 444.879, 1, 0, 0.50234,-99)    );
  // itree = 35
  fBoostWeights.push_back(0.05754);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.628613,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.499682,-99) , 
0, 0.213348, 1, 0, 0.52501,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501691,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.43509,-99) , 
4, 0.0527431, 0, 0, 0.485007,-99) , 
0, -0.255754, 0, 0, 0.507147,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511169,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.457178,-99) , 
5, 0.863995, 0, 0, 0.476384,-99) , 
1, 1100.03, 0, 0, 0.500729,-99)    );
  // itree = 36
  fBoostWeights.push_back(0.0736354);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.626153,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.568283,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.490487,-99) , 
4, 0.0509688, 1, 0, 0.503938,-99) , 
0, 0.213348, 1, 0, 0.520956,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.537154,-99) , 
NN(
0, 
0, 
-1, 0.568256, 0, -1, 0.475161,-99) , 
8, 278.817, 1, 0, 0.483292,-99) , 
0, -0.118662, 0, 0, 0.502901,-99)    );
  // itree = 37
  fBoostWeights.push_back(0.0568936);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0.213348, 1, 1, 0.528849,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.563944,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.496093,-99) , 
5, 0.321633, 1, 0, 0.505248,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.441828,-99) , 
5, 0.155724, 0, 0, 0.496898,-99) , 
0, -0.118662, 0, 0, 0.513528,-99)    );
  // itree = 38
  fBoostWeights.push_back(0.0821503);
  fForest.push_back( 
NN(
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.566602,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.483466,-99) , 
5, 0.877511, 1, 0, 0.538984,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.525418,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.473358,-99) , 
2, 0.927207, 1, 0, 0.506887,-99) , 
4, 0.102485, 0, 0, 0.517136,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.531662,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.46006,-99) , 
0, -0.23903, 1, 0, 0.489517,-99) , 
1, 1100.03, 0, 0, 0.511374,-99)    );
  // itree = 39
  fBoostWeights.push_back(0.0785558);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 113.084, 1, 1, 0.54571,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.509772,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.438614,-99) , 
5, 0.820808, 0, 0, 0.50078,-99) , 
5, 0.753425, 1, 0, 0.515241,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.57016,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.465288,-99) , 
8, 422.642, 1, 0, 0.524849,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.511861,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.421066,-99) , 
8, 338.036, 0, 0, 0.470195,-99) , 
7, -1.68556, 1, 0, 0.4905,-99) , 
5, 0.415705, 0, 0, 0.507243,-99)    );
  // itree = 40
  fBoostWeights.push_back(0.0822281);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.575405,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.523741,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.466931,-99) , 
7, 1.64381, 1, 0, 0.494631,-99) , 
6, 83.0712, 0, 0, 0.512411,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.563876,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.48144,-99) , 
4, 0.11956, 1, 0, 0.507077,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.501483,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.437016,-99) , 
5, 0.777055, 1, 0, 0.469939,-99) , 
4, 0.0963807, 0, 0, 0.487911,-99) , 
6, 93.7701, 1, 0, 0.495581,-99)    );
  // itree = 41
  fBoostWeights.push_back(0.0708546);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.555794,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.515043,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.445609,-99) , 
4, 0.131219, 0, 0, 0.498681,-99) , 
4, 0.11956, 1, 0, 0.51368,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.522341,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.478732,-99) , 
6, 94.1131, 1, 0, 0.495843,-99) , 
NN(
0, 
0, 
-1, 0.449247, 0, -1, 0.446297,-99) , 
4, 0.0893173, 1, 0, 0.486625,-99) , 
4, 0.103305, 0, 0, 0.496726,-99)    );
  // itree = 42
  fBoostWeights.push_back(0.0243023);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.571308,-99) , 
NN(
0, 
0, 
-1, 73.1303, 0, -1, 0.496059,-99) , 
6, 62.1871, 1, 0, 0.499759,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.44903,-99) , 
6, 47.3673, 0, 0, 0.496426,-99)    );
  // itree = 43
  fBoostWeights.push_back(0.0336865);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0.194818, 1, 1, 0.509197,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452798,-99) , 
2, 0.0900426, 0, 0, 0.505262,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.45494,-99) , 
6, 47.4303, 0, 0, 0.501953,-99)    );
  // itree = 44
  fBoostWeights.push_back(0.0962682);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 399.896, 1, 1, 0.558085,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.5109,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.412432,-99) , 
5, 0.359987, 0, 0, 0.483269,-99) , 
2, 0.942993, 0, 0, 0.509965,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.529433,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.475315,-99) , 
3, 0.449353, 0, 0, 0.501762,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.524373,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.412599,-99) , 
7, -2.55169, 1, 0, 0.457415,-99) , 
2, 0.953434, 1, 0, 0.48658,-99) , 
7, 1.92257, 0, 0, 0.495736,-99)    );
  // itree = 45
  fBoostWeights.push_back(0.0309204);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.543573,-99) , 
NN(
0, 
0, 
-1, 2.91272, 1, -1, 0.488513,-99) , 
3, 0.0810365, 1, 0, 0.490903,-99)    );
  // itree = 46
  fBoostWeights.push_back(0.0254682);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.559806,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.500666,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.451897,-99) , 
2, 0.998049, 1, 0, 0.496494,-99) , 
1, 2277.17, 0, 0, 0.500869,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.467583,-99) , 
0, -1.70018, 0, 0, 0.49797,-99)    );
  // itree = 47
  fBoostWeights.push_back(0.0426604);
  fForest.push_back( 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.535192,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.558955,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.49261,-99) , 
1, 1941.47, 0, 0, 0.49932,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.504154,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.452263,-99) , 
5, 0.982948, 0, 0, 0.477318,-99) , 
5, 0.906305, 1, 0, 0.492199,-99) , 
1, 2727, 0, 0, 0.493637,-99)    );
  // itree = 48
  fBoostWeights.push_back(0.057427);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.570132,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.50698,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.431865,-99) , 
4, 0.0360049, 0, 0, 0.50186,-99) , 
3, 0.105731, 1, 0, 0.506182,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.5707,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.475738,-99) , 
3, 0.496482, 1, 0, 0.50976,-99) , 
NN(
0, 
0, 
-1, 0.991172, 0, -1, 0.434294,-99) , 
3, 0.336819, 0, 0, 0.476683,-99) , 
5, 0.954311, 1, 0, 0.498963,-99)    );
  // itree = 49
  fBoostWeights.push_back(0.0548383);
  fForest.push_back( 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.5502,-99) , 
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.514714,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.482863,-99) , 
8, 362.666, 1, 0, 0.493501,-99) , 
1, 2727, 0, 0, 0.495476,-99) , 
NN(
NN(
NN(
0, 
0, 
-1, 0, 1, 1, 0.532083,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.473533,-99) , 
6, 59.2132, 1, 0, 0.500662,-99) , 
NN(
0, 
0, 
-1, 0, 1, -1, 0.442786,-99) , 
3, 0.464386, 1, 0, 0.479607,-99) , 
6, 83.0712, 0, 0, 0.491599,-99)    );
   return;
};
 
// Clean up
inline void ReadBDT_VBF0HighVPtHighMJJ::Clear() 
{
   for (unsigned int itree=0; itree<fForest.size(); itree++) { 
      delete fForest[itree]; 
   }
}
   inline double ReadBDT_VBF0HighVPtHighMJJ::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
